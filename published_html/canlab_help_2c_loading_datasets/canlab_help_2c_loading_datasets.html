
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Datasets used in CANlab tutorials</title><meta name="generator" content="MATLAB 9.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2023-08-25"><meta name="DC.source" content="canlab_help_2c_loading_datasets.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:14px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.8em; color:#2C2D92; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.4em; color:#363538; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#363538; font-weight:bold; line-height:140%; }

a { color:#4B4BA8; text-decoration:none; }
a:hover { color:#2AAFDF; text-decoration:underline; }
a:visited { color:#4B4BA8; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:14px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Datasets used in CANlab tutorials</h1><!--introduction--><p>Note: this report was generated from <tt>canlab_help_2c_loading_datasets.m</tt> in the repository <a href="https://github.com/canlab/CANlab_help_examples">https://github.com/canlab/CANlab_help_examples</a></p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">The Neuroimaging_pattern_masks Github repository and website</a></li><li><a href="#2">Registries for easy loading</a></li><li><a href="#3">Emotion regulation dataset</a></li><li><a href="#4">Buckner lab resting-state connectivity maps</a></li><li><a href="#5">Pain, Cognition, Emotion balanced N = 270 dataset</a></li><li><a href="#6">Pain across six intensity levels per person (BMRK3)</a></li><li><a href="#7">CANlab 2018 Combined Atlas object</a></li><li><a href="#8">Kragel 2015 emotion category-predictive patterns</a></li><li><a href="#9">Subcortical and brainstem regions</a></li></ul></div><h2 id="1">The Neuroimaging_pattern_masks Github repository and website</h2><p>For these walkthroughs, we'll load several image datasets. Some are stored in Github, if the files are small enough. The Wager 2008 emotion regulation dataset, for example, is in the CANlab Core repository. Others are on figshare or Neurovault.</p><p>Many tutorials apply pre-trained patterns and masks. These are stored in this Github repository:</p><p><a href="https://github.com/canlab/Neuroimaging_Pattern_Masks">https://github.com/canlab/Neuroimaging_Pattern_Masks</a></p><p>In addition, you can explore these and find more information here: <a href="https://sites.google.com/dartmouth.edu/canlab-brainpatterns/home">https://sites.google.com/dartmouth.edu/canlab-brainpatterns/home</a></p><p>To run this tutorial and many others in this series, you'll need to download the Neuroimaging_Pattern_Masks Github repository and add it to your Matlab path with subfolders. The Github site has three main types of datasets, shown here:</p><p><img vspace="5" hspace="5" src="Neuroimaging_pattern_masks_site.png" alt=""> </p><h2 id="2">Registries for easy loading</h2><p>There are several functions that contain sets of images that you can load by name. For example:</p><p><tt>load_image_set()</tt> includes a registry of datasets that you can access by name. Try <tt>help load_image|set</tt> for a list of images you can load by keyword.</p><p><tt>load_atlas()</tt> also has a named set of atlases/brain parcellations you can load.</p><p><tt>canlab_load_ROI</tt> has a registry of many named regions derived from previous studies. This is particularly useful for loading a subcortical ROI and visualizing it or applying it to data.</p><h2 id="3">Emotion regulation dataset</h2><p>"Wager_et_al_2008_Neuron_EmotionReg" The dataset is a series of contrast images from N = 30 participants. Each image is a contrast image for [reappraise neg vs. look neg]</p><p>These data were published in: Wager, T. D., Davidson, M. L., Hughes, B. L., Lindquist, M. A., Ochsner, K. N.. (2008). Prefrontal-subcortical pathways mediating successful emotion regulation. Neuron, 59, 1037-50.</p><p>To load, try the following:</p><pre class="codeinput">[data_obj, subject_names, image_names] = load_image_set(<span class="string">'emotionreg'</span>, <span class="string">'noverbose'</span>);

montage(mean(data_obj), <span class="string">'trans'</span>, <span class="string">'compact2'</span>);
drawnow, snapnow

<span class="comment">% data_obj is an fmri_data object containing all 30 images.</span>
<span class="comment">% subject_names is a list of short names for each image.</span>
<span class="comment">% image_names is a list of the full image names with their path.</span>
</pre><pre class="codeoutput">Direct calls to spm_defauts are deprecated.
Please use spm('Defaults',modality) or spm_get_defaults instead.
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Setting up fmridisplay objects
axial montage: 16574 voxels displayed, 19102 not displayed on these slices
sagittal montage: 2230 voxels displayed, 33446 not displayed on these slices
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_01.png" alt=""> <h2 id="4">Buckner lab resting-state connectivity maps</h2><p>A popular series of masks is a set of "networks" developed from resting-state fMRI connectivity in 1,000 people. For our purposes, the "network" maps consist of a set of voxels that load most highly on each of 7 ICA components from the 1,000 Functional Connectomes project. These were published by Randy Buckner's lab in 2011 in three papers: Choi et al., Buckner et al., and Yeo et al.  We'll use the cortical networks from Yeo et al. here.</p><pre class="codeinput">[bucknermaps, mapnames] = load_image_set(<span class="string">'bucknerlab'</span>, <span class="string">'noverbose'</span>); <span class="comment">% loads 7 masks from Yeo et al.</span>
disp(char(mapnames))

<span class="comment">% Create a montage plot</span>
o2 = montage(get_wh_image(bucknermaps, 1), <span class="string">'trans'</span>, <span class="string">'compact2'</span>, <span class="string">'color'</span>, rand(1, 3));
<span class="keyword">for</span> i = 2:7, o2 = addblobs(o2, region(get_wh_image(bucknermaps, i)), <span class="string">'trans'</span>, <span class="string">'color'</span>, rand(1, 3)); <span class="keyword">end</span>
drawnow, snapnow
</pre><pre class="codeoutput">Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Visual        
Somatomotor   
dAttention    
vAttention    
Limbic        
Frontoparietal
Default       
Setting up fmridisplay objects
axial montage: 5637 voxels displayed, 16451 not displayed on these slices
sagittal montage: 658 voxels displayed, 21430 not displayed on these slices
No variability in mapped values. Not plotting legend.
Grouping contiguous voxels:   1 regions
axial montage: 2819 voxels displayed, 16654 not displayed on these slices
sagittal montage: 498 voxels displayed, 18975 not displayed on these slices
Grouping contiguous voxels:   7 regions
axial montage: 2403 voxels displayed, 12844 not displayed on these slices
sagittal montage: 132 voxels displayed, 15115 not displayed on these slices
Grouping contiguous voxels:  11 regions
axial montage: 3137 voxels displayed, 10511 not displayed on these slices
sagittal montage: 521 voxels displayed, 13127 not displayed on these slices
Grouping contiguous voxels:   1 regions
axial montage: 2174 voxels displayed, 9345 not displayed on these slices
sagittal montage: 338 voxels displayed, 11181 not displayed on these slices
Grouping contiguous voxels:  16 regions
axial montage: 4378 voxels displayed, 15124 not displayed on these slices
sagittal montage: 487 voxels displayed, 19015 not displayed on these slices
Grouping contiguous voxels:  10 regions
axial montage: 7133 voxels displayed, 22886 not displayed on these slices
sagittal montage: 1583 voxels displayed, 28436 not displayed on these slices
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_02.png" alt=""> <h2 id="5">Pain, Cognition, Emotion balanced N = 270 dataset</h2><p>This dataset is an fmri_data object class object created using CANlab tools (canlab.github.io). It contains 270 single-participant fMRI contrast maps across 18 studies (with 15 participants per study). Studies are grouped into three domains: Pain, Cognitive Control, and Negative Emotion, with 9 studies each. Each domain includes 3 subdomains, with 3 studies each.</p><p>The dataset is from Kragel et al. 2018, Nature Neuroscience. It is too large for Github, and it's stored on Neurovault.org as collection #504. You could get it using CANlab tools like this:</p><p><tt>[files_on_disk, url_on_neurovault, mycollection, myimages] = retrieve_neurovault_collection(504);</tt></p><p>It is also available on Figshare, with DOI 10.6084/m9.figshare.24033402 <a href="https://figshare.com/ndownloader/files/42143352">https://figshare.com/ndownloader/files/42143352</a></p><p>If you download from Neurovault, you'd have to add metadata for the study category labels to use it. Therefore, we suggest you use the CANLab load_image_set() function, as below. It saves a file on your hard drive the first time you run it:</p><p><tt>kragel_2018_nat_neurosci_270_subjects_test_images.mat</tt></p><p>This file also has metadata that is not necessarily on Neurovault. If you save this file somewhere on your Matlab path, you'll be able to reload and reuse the dataset easily.</p><pre class="codeinput">[test_images, names] = load_image_set(<span class="string">'kragel18_alldata'</span>, <span class="string">'noverbose'</span>);

<span class="comment">% This field contains a table object with metadata for each image:</span>
metadata = test_images.metadata_table;

disp(<span class="string">'Metadata available in test_images.metadata_table:'</span>)
metadata(1:5, :)

<span class="comment">% Make a plot of the spatial correlation of the average image for each study</span>

imgs = cellstr(test_images.image_names);
m = mean(test_images);

<span class="keyword">for</span> i = 1:length(names)

    <span class="comment">% Create a mean image for each study and store in "m" object.</span>

    wh = metadata.Studynumber == i;
    studymean = mean(get_wh_image(test_images, find(wh)));
    m.dat(:, i) = studymean.dat;

<span class="keyword">end</span>

disp(<span class="string">'Map of spatial correlations across the mean images for each study'</span>);

plot_correlation_matrix(m.dat, <span class="string">'names'</span>, names, <span class="string">'partitions'</span>, [ones(1, 6) 2*ones(1, 6) 3*ones(1, 6)], <span class="string">'partitionlabels'</span>, {<span class="string">'Pain'</span>, <span class="string">'Cognition'</span>, <span class="string">'Emotion'</span>});
drawnow, snapnow
</pre><pre class="codeoutput">Loading /Users/f003vz1/Downloads/kragel_2018_nat_neurosci_270_subjects_test_images.mat
Metadata available in test_images.metadata_table:

ans =

  5&times;6 table

     Domain      Subdomain        imagenames       Studynumber    Orig_Studynumber        StudyCodes    
    ________    ___________    ________________    ___________    ________________    __________________

    {'Pain'}    {'Thermal'}    {'ThermalPain1'}         1                10           {'Atlas_2010_EXP'}
    {'Pain'}    {'Thermal'}    {'ThermalPain1'}         1                10           {'Atlas_2010_EXP'}
    {'Pain'}    {'Thermal'}    {'ThermalPain1'}         1                10           {'Atlas_2010_EXP'}
    {'Pain'}    {'Thermal'}    {'ThermalPain1'}         1                10           {'Atlas_2010_EXP'}
    {'Pain'}    {'Thermal'}    {'ThermalPain1'}         1                10           {'Atlas_2010_EXP'}

Map of spatial correlations across the mean images for each study
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_03.png" alt=""> <h2 id="6">Pain across six intensity levels per person (BMRK3)</h2><p>The dataset contains data from 33 participants, with brain responses to six levels of heat (non-painful and painful). Each image is the average over several (4-8) trials of heat delivered at a single stimulus intensity, ranging from 44.3 - 49.3 degrees C in one-degree increments. Each image is also paired with an average reported pain value for that set of trials, rated immmediately after heat experience.</p><p>This dataset is interesting for mixed-effects and predictive analyses, as it has both within-person and between-person sources of variance.</p><p>Aspects of this data appear in these papers: Wager, T.D., Atlas, L.T., Lindquist, M.A., Roy, M., Choong-Wan, W., Kross, E. (2013). An fMRI-Based Neurologic Signature of Physical Pain. The New England Journal of Medicine. 368:1388-1397 (Study 2)</p><p>Woo, C. -W., Roy, M., Buhle, J. T. &amp; Wager, T. D. (2015). Distinct brain systems mediate the effects of nociceptive input and self-regulation on pain. PLOS Biology. 13(1): e1002036. doi:10.1371/journal.pbio.1002036</p><p>Lindquist, Martin A., Anjali Krishnan, Marina L&oacute;pez-Sol&agrave;, Marieke Jepma, Choong-Wan Woo, Leonie Koban, Mathieu Roy, et al. 2015. ?Group-Regularized Individual Prediction: Theory and Application to Pain.? NeuroImage. <a href="http://www.sciencedirect.com/science/article/pii/S1053811915009982">http://www.sciencedirect.com/science/article/pii/S1053811915009982</a>.</p><p>This dataset is shared on figshare.com, under this link: <a href="https://figshare.com/s/ca23e5974a310c44ca93">https://figshare.com/s/ca23e5974a310c44ca93</a></p><p>Here is a direct link to the dataset file with the fmri_data object: <a href="https://ndownloader.figshare.com/files/12708989">https://ndownloader.figshare.com/files/12708989</a></p><p>The key variable is image_obj, an fmri_data class object. See <a href="https://canlab.github.io/">https://canlab.github.io/</a></p><p>image_obj.dat contains brain data for each image (average across trials) image_obj.Y contains pain ratings (one average rating per image)</p><p>image_obj.additional_info.subject_id contains integers coding for which Load the data file, downloading from figshare if needed</p><pre class="codeinput">fmri_data_file = which(<span class="string">'bmrk3_6levels_pain_dataset.mat'</span>);

<span class="keyword">if</span> isempty(fmri_data_file)

    <span class="comment">% attempt to download</span>
    disp(<span class="string">'Did not find data locally...downloading data file from figshare.com'</span>)

    fmri_data_file = websave(<span class="string">'bmrk3_6levels_pain_dataset.mat'</span>, <span class="string">'https://ndownloader.figshare.com/files/12708989'</span>);

<span class="keyword">end</span>

load(fmri_data_file);

descriptives(image_obj);

subject_id = image_obj.additional_info.subject_id;
ratings = reshape(image_obj.Y, 6, 33)';
temperatures = image_obj.additional_info.temperatures;

<span class="comment">% Plot the ratings</span>

create_figure(<span class="string">'ratings'</span>);
title(<span class="string">'Pain ratings by stimulus intensity in BMRK3 dataset'</span>)
hold <span class="string">on</span>; plot(ratings', <span class="string">'-'</span>, <span class="string">'Color'</span>, [.7 .7 .7], <span class="string">'LineWidth'</span>, .5);
lineplot_columns(ratings, <span class="string">'color'</span>, [.7 .3 .3], <span class="string">'markerfacecolor'</span>, [1 .5 0]);
xlabel(<span class="string">'Temperature'</span>);
ylabel(<span class="string">'Rating'</span>);
set(gca, <span class="string">'XTickLabel'</span>, [44.3:49.3], <span class="string">'FontSize'</span>, 18);
drawnow, snapnow
</pre><pre class="codeoutput">Did not find data locally...downloading data file from figshare.com
 
Source: BMRK3 dataset from CANlab, PI Tor Wager
Data: .dat contains 6 images per participant, activation estimates during heat on L arm from level 1(44.3 degrees C) to level 6(49.3), in 1 degree increments.
 

____________________________________________________________________________________________________________________________________________
 Wager, T.D., Atlas, L.T., Lindquist, M.A., Roy, M., Choong-Wan, W., Kross, E. (2013). An fMRI-Based Neurologic Signature of Physical Pain. 
The New England Journal of Medicine. 368:1388-1397 (Study 2)                                                                                
                                                                                                                                            
 Woo, C. -W., Roy, M., Buhle, J. T. &amp; Wager, T. D. (2015). Distinct brain systems mediate the effects of nociceptive input and 
self-regulation on pain. PLOS Biology. 13(1): e1002036. doi:10.1371/journal.pbio.1002036                                       
                                                                                                                               
Lindquist, Martin A., Anjali Krishnan, Marina L&oacute;pez-Sol&agrave;, Marieke Jepma, Choong-Wan Woo, Leonie Koban, Mathieu Roy, et al. 2015. 
&#8220;Group-Regularized Individual Prediction: Theory and Application to Pain.&#8221; NeuroImage.                                           
http://www.sciencedirect.com/science/article/pii/S1053811915009982.                                                              
                                                                                                                                 
____________________________________________________________________________________________________________________________________________
 
Summary of dataset
______________________________________________________
Images: 198	Nonempty: 198	Complete: 198
  Images missing &gt;50% of voxels:   0	
Number of unique values in dataset: 35583281  Bit rate: 25.08 bits
Warning: Number of unique values in dataset is low, indicating possible restriction of bit rate. For comparison, Int16 has 65,536 unique values
  Images missing &gt;10% of voxels:   0	
Voxels: 223707	Nonempty (1+ images have valid data): 223707	Complete  (all images have data): 223707
Unique data values: 35583281
 
Min: -11.529	Max: 7.862	Mean: -0.004	Std: 0.227
 
    Percentiles      Values  
    ___________    __________

        0.1            -1.529
        0.5          -0.88055
          1          -0.67632
          5          -0.31891
         25         -0.087519
         50        0.00034864
         75          0.087461
         95           0.29757
         99           0.60449
       99.5           0.77676
       99.9            1.3177

 
Saved desc.coverage_obj_binned with maps of number of valid images,
and desc.coverage_obj_binned with values of 100=100% valid images, 80=80-99.9% valid, 50=50-80% valid, and 1=&gt;50% valid images
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_04.png" alt=""> <h2 id="7">CANlab 2018 Combined Atlas object</h2><p>An atlas-class object is a specialized subclass of fmri_data that stores information about a series of parcels, or pre-defined regions, and in some cases the probalistic maps that underlie the final parcellation.</p><p>A list of pre-defined atlases is contained in the function <tt>load_atlas</tt>. The default atlas for some CANlab functions is the "CANlab combined 2018" This was created by Tor Wager from other published atlases. It includes:</p><div><ul><li>Glasser 2016 Nature 180-region cortical parcellation (in MNI space, not indivdidualized)</li><li>Pauli 2016 PNAS basal ganglia subregions</li><li>Amygdala/hippocampal and basal forebrain regions from SPM Anatomy Toolbox</li><li>Thalamus regions from the Morel thalamus atlas</li><li>Subthalamus/Basal forebrain regions from Pauli "reinforcement learning" HCP atlas</li><li>Diedrichsen cerebellar atlas regions</li><li>Multiple named brainstem nuclei localized based on individual papers</li><li>Additional Shen atlas parcels to cover areas (esp. brainstem) not otherwise named</li></ul></div><p>References for the corresponding papers are stored in the atlas object, and printed in tables generated with the region.table() method.</p><pre class="codeinput">atlas_obj = load_atlas(<span class="string">'canlab2018'</span>);

<span class="comment">% Create a figure showing cortical parcels</span>
create_figure(<span class="string">'iso'</span>); isosurface(atlas_obj, <span class="string">'alpha'</span>, .5);
drawnow, snapnow

<span class="comment">% Create a figure of the thalamus regions only</span>
thal = select_atlas_subset(atlas_obj, {<span class="string">'Thal'</span>});
create_figure(<span class="string">'iso'</span>); isosurface(thal);
hh = addbrain(<span class="string">'hires'</span>);
set(hh, <span class="string">'FaceAlpha'</span>, 0.05);
set(gca, <span class="string">'XLim'</span>, [-40 40], <span class="string">'YLim'</span>, [-40 20]);
drawnow, snapnow
</pre><pre class="codeoutput">Loading atlas: CANlab_combined_atlas_object_2018.mat
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_05.png" alt=""> <img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_06.png" alt=""> <h2 id="8">Kragel 2015 emotion category-predictive patterns</h2><p>This loads a series of 7 multivariate patterns from Kragel et al. 2015. These patterns were developed to predict emotion categories. For our purposes here, we'll just treat them as data images.</p><pre class="codeinput">[test_dat, names] = load_image_set(<span class="string">'kragelemotion'</span>, <span class="string">'noverbose'</span>); <span class="comment">% loads 7 masks from Kragel et al.</span>
disp(char(names))

<span class="comment">% Plot spatial correlations</span>
plot_correlation_matrix(test_dat.dat, <span class="string">'names'</span>, names);
drawnow, snapnow
</pre><pre class="codeoutput">Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Amused   
Angry    
Content  
Fearful  
Neutral  
Sad      
Surprised
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_07.png" alt=""> <h2 id="9">Subcortical and brainstem regions</h2><p><tt>canlab_load_ROI</tt> has a registry of many named regions derived from previous studies. This is particularly useful for loading a subcortical ROI and visualizing it or applying it to data.</p><pre class="codeinput">help <span class="string">canlab_load_ROI</span>

vmpfc = canlab_load_ROI(<span class="string">'vmpfc'</span>);
nac =  canlab_load_ROI(<span class="string">'nac'</span>);
pag =  canlab_load_ROI(<span class="string">'pag'</span>);

create_figure(<span class="string">'brain'</span>);
isosurface(vmpfc, <span class="string">'color'</span>, {[1 0 1]});
isosurface(nac, <span class="string">'color'</span>, {[1 .5 0]});
isosurface(pag, <span class="string">'color'</span>, {[1 0 0]});
bhan = addbrain(<span class="string">'hires right'</span>);
view(-119, 5);
drawnow, snapnow
</pre><pre class="codeoutput">  Load a region by name (hand-picked from various atlases), for display or use as ROI in analysis
 
  - r is a region object, useful for display (e.g., addbrain.m and any region object method)
  - atlas_obj is an atlas object containing regions, mapped to a standard reference space (1 mm res)
    this can be slow for some objects and is not needed for region display
    (e.g., addblobs.m), so 'noatlas' will return an empty atlas_obj instead
 
  - Easy to add regions from region objects or binary masks (.nii/.img)
  - Some regions best for display only; some good as ROIs as well
  - Inter-operates with addbrain.m to load regions for display
 
 
  :Usage:
  ::
 
     [r, atlas_obj, default_color, region_file, image_file] = canlab_load_ROI(region_name,[optional arguments])
 
  Working options:
  -----------------------------------------------------------
  {'vmpfc' 'nacc' 'BST' ...
      'cau' 'caudate' 'put' 'GP' 'GPe' 'GPi' 'VeP' ...
      'thalamus' 'thal' 'cm' 'md' 'stn' 'habenula' 'mammillary' 'hypothalamus','hy','hythal' ...
      'brainstem' 'midbrain' 'pag' 'PBP' 'sn' 'SNc' 'SNr' 'VTA' 'rn' ...
      'pbn' 'lc' 'rvm' 'rvm_old' 'nts' 'drn' 'mrn' 'sc' 'ic'}
      
  Cortex -----------------------------------------------------------
  'vmpfc'   Ventromedial prefrontal + posterior cing, midline; hand-drawn (Tor Wager)
 
  Forebrain (non-basal ganglia)
  -----------------------------------------------------------
  'nacc'    Nucleus accumbens               % Pauli 2017 BioArxiv subcortical atlas
  'hipp'    Hippocampus                     % SPM Anatomy Toolbox, as stored in Canlab2018_combined atlas
  'BST'     Bed nuc. of stria term/SLEA     % Pauli 2017 BioArxiv subcortical atlas
 
  Basal ganglia
  -----------------------------------------------------------
  'caudate'  Caudate nucleus
  'put'      Putamen            % MISSING
  'GP'       Globus pallidus; Keuken 2014
  'GPe'       Globus pallidus internal; Keuken 2014
  'GPi'       Globus pallidus external; Keuken 2014
  'VeP'        Ventral pallidum           % Pauli 2017 BioArxiv subcortical atlas
 
   Thalamus, Diencephalon, Epithalamus
  -----------------------------------------------------------
  'thalamus'                        Morel thalamus main body, Krauth 2010
  'cm'      Centromedian thalamus   Morel thalamus atlas, Krauth 2010
  'md'      Mediodorsal thalamus    Morel thalamus atlas, Krauth 2010
  'stn'     subthalamic nucleus     Keuken 2014 (also options in Pauli, Morel)
  'habenula'     Habenula           Pauli 2017 BioArxiv subcortical atlas (also in Morel)
  'mammillary'   Mammillary bodies  Pauli 2017 BioArxiv subcortical atlas
  'lgn'     Lateral geniculate nuc  Morel thalamus atlas, Krauth 2010
  'mgn'     Medial geniculate nuc   Morel thalamus atlas, Krauth 2010
  'VPthal'  Ventral posterior thal  Morel thalamus atlas, Krauth 2010
  'intralaminar_thal' Intralaminar  Morel thalamus atlas, Krauth 2010
 
  Brainstem
  -----------------------------------------------------------
  'brainstem'  Segmented and cleaned (Tor Wager) from SPM8 tissue probability maps
  'midbrain'   Overall midbrain, from Carmack 2004
  'pag'        Periaqueductal gray, hand-drawn (Tor Wager 2018, mask out aqueduct/Keuken2014)
  'sc'         Superior colliculus, hand-drawn (Tor Wager 2018, mask out aqueduct/Keuken2014)
  'ic'         Inferior colliculus, hand-drawn (Tor Wager 2018, mask out aqueduct/Keuken2014)
  'drn'        Dorsal raphe nucleus, coords from Beliveau, 2015. Beliveau, Vincent, Claus Svarer, Vibe G. Frokjaer, Gitte M. Knudsen, Douglas N. Greve, and Patrick M. Fisher. 2015. ?Functional Connectivity of the Dorsal and Median Raphe Nuclei at Rest.? NeuroImage 116 (August): 187?95.
  'mrn'        Median raphe nucleus, coords from Beliveau, 2015. Beliveau, Vincent, Claus Svarer, Vibe G. Frokjaer, Gitte M. Knudsen, Douglas N. Greve, and Patrick M. Fisher. 2015. ?Functional Connectivity of the Dorsal and Median Raphe Nuclei at Rest.? NeuroImage 116 (August): 187?95.
  'PBP'        Parabrachial pigmented nuc.      % Pauli 2017 BioArxiv subcortical atlas
  'sn'         Substantia Nigra; Keuken 2014   % Keuken, M. C., P-L Bazin, L. Crown, J. Hootsmans, A. Laufer, C. M&uuml;ller-Axt, R. Sier, et al. 2014. ?Quantifying Inter-Individual Anatomical Variability in the Subcortex Using 7 T Structural MRI.? NeuroImage 94 (July): 40?46.
  'SNc'        Substantia Nigra compacta        % Pauli 2017 BioArxiv subcortical atlas
  'SNr'        Substantia Nigra reticularis     % Pauli 2017 BioArxiv subcortical atlas
  'VTA'        Ventral tegmental area           % Pauli 2017 BioArxiv subcortical atlas
  'rn'         Red nucleus; Keuken 2014
  'pbn'        Parabrachial complex; Fairhurst, Merle, Katja Wiech, Paul Dunckley, and Irene Tracey. 2007. ?Anticipatory Brainstem Activity Predicts Neural Processing of Pain in Humans.? Pain 128 (1-2):101?10.
  'lc'         Locus coeruleus; Keren 2009, 2SD image
  'rvm_old'    Hand-drawn rostral ventral medulla (Tor) in anatomical rvm
  'rvm'        Rostral ventral medulla from Brooks et al. 2016(??)
  'nts'        Nuc. tractus solitarius (rough; hand-drawn, Tor)
  'olive'      Inferior olive; MISSING
  'nrm'        Nuc. raphe magnus; % B&auml;r, Karl-J&uuml;rgen, Feliberto de la Cruz, Andy Schumann, Stefanie Koehler, Heinrich Sauer, Hugo Critchley, and Gerd Wagner. 2016. ?Functional Connectivity and Network Analysis of Midbrain and Brainstem Nuclei.? NeuroImage 134 (July):53?63.
  'ncf'        Nuc. cuneiformis; Zambreanu, L., R. G. Wise, J. C. W. Brooks, G. D. Iannetti, and I. Tracey. 2005. ?A Role for the Brainstem in Central Sensitisation in Humans. Evidence from Functional Magnetic Resonance Imaging.? Pain 114 (3):397?407.
  'ncs_B6_B8'  B&auml;r, Karl-J&uuml;rgen, Feliberto de la Cruz, Andy Schumann, Stefanie Koehler, Heinrich Sauer, Hugo Critchley, and Gerd Wagner. 2016. ?Functional Connectivity and Network Analysis of Midbrain and Brainstem Nuclei.? NeuroImage 134 (July):53?63.
  'nrp_B5'     B&auml;r, Karl-J&uuml;rgen, Feliberto de la Cruz, Andy Schumann, Stefanie Koehler, Heinrich Sauer, Hugo Critchley, and Gerd Wagner. 2016. ?Functional Connectivity and Network Analysis of Midbrain and Brainstem Nuclei.? NeuroImage 134 (July):53?63.
  'nuc_ambiguus' Sclocco, Roberta, Florian Beissner, Gaelle Desbordes, Jonathan R. Polimeni, Lawrence L. Wald, Norman W. Kettner, Jieun Kim, et al. 2016. ?Neuroimaging Brainstem Circuitry Supporting Cardiovagal Response to Pain: A Combined Heart Rate Variability/ultrahigh-Field (7 T) Functional Magnetic Resonance Imaging Study.? Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 374 (2067). rsta.royalsocietypublishing.org. https://doi.org/10.1098/rsta.2015.0189.
  'dmnx_nts'    Sclocco, Roberta, Florian Beissner, Gaelle Desbordes, Jonathan R. Polimeni, Lawrence L. Wald, Norman W. Kettner, Jieun Kim, et al. 2016. ?Neuroimaging Brainstem Circuitry Supporting Cardiovagal Response to Pain: A Combined Heart Rate Variability/ultrahigh-Field (7 T) Functional Magnetic Resonance Imaging Study.? Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 374 (2067). rsta.royalsocietypublishing.org. https://doi.org/10.1098/rsta.2015.0189.
  'vep'          % Pauli 2017 BioArxiv CIT168 subcortical atlas 
  'medullary_raphe' Nash, Paul G., Vaughan G. Macefield, Iven J. Klineberg, Greg M. Murray, and Luke A. Henderson. 2009. ?Differential Activation of the Human Trigeminal Nuclear Complex by Noxious and Non-Noxious Orofacial Stimulation.? Human Brain Mapping 30 (11):3772?82.
  'spinal_trigeminal' Nash, Paul G., Vaughan G. Macefield, Iven J. Klineberg, Greg M. Murray, and Luke A. Henderson. 2009. ?Differential Activation of the Human Trigeminal Nuclear Complex by Noxious and Non-Noxious Orofacial Stimulation.? Human Brain Mapping 30 (11):3772?82.
 
  Examples:
 
  [r, obj, default_color, region_file, image_file] = canlab_load_ROI('vmpfc');
  orthviews(r, 'color', {default_color});
 
  [r, myatlas] = canlab_load_ROI('habenula'); num_regions(myatlas); orthviews(myatlas)
  r = canlab_load_ROI('habenula', 'noatlas'); orthviews(r)

Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Grouping contiguous voxels:   2 regions
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
Defaults settings have been modified by file(s):
  /Users/f003vz1/Dropbox (Dartmouth College)/Matlab_code_external/spm12/spm_my_defaults.m
Modified fields: stats 
</pre><img vspace="5" hspace="5" src="canlab_help_2c_loading_datasets_08.png" alt=""> <p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2022b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Datasets used in CANlab tutorials
%
% Note: this report was generated from |canlab_help_2c_loading_datasets.m|
% in the repository <https://github.com/canlab/CANlab_help_examples>
%

%% The Neuroimaging_pattern_masks Github repository and website
%
% For these walkthroughs, we'll load several image datasets.
% Some are stored in Github, if the files are small enough.
% The Wager 2008 emotion regulation dataset, for example, is
% in the CANlab Core repository. Others are on figshare or Neurovault.
%
% Many tutorials apply pre-trained patterns and masks. 
% These are stored in this Github repository:
% 
% <https://github.com/canlab/Neuroimaging_Pattern_Masks>
% 
% In addition, you can explore these and find more information here:
% <https://sites.google.com/dartmouth.edu/canlab-brainpatterns/home>
%
% To run this tutorial and many others in this series, you'll need to
% download the Neuroimaging_Pattern_Masks Github repository and add it to
% your Matlab path with subfolders.
% The Github site has three main types of datasets, shown here:
% 
% <<Neuroimaging_pattern_masks_site.png>>
%
%% Registries for easy loading
% There are several functions that contain sets of images that you can load
% by name. For example:
%
% |load_image_set()| includes a registry of datasets that you can access by
% name. Try |help load_image|set| for a list of images you can load by
% keyword.  
%
% |load_atlas()| also has a named set of atlases/brain parcellations you can load.
%
% |canlab_load_ROI| has a registry of many named regions derived from previous
% studies. This is particularly useful for loading a subcortical ROI and
% visualizing it or applying it to data.

%% Emotion regulation dataset
% "Wager_et_al_2008_Neuron_EmotionReg"
% The dataset is a series of contrast images from N = 30 participants.
% Each image is a contrast image for [reappraise neg vs. look neg]
% 
% These data were published in:
% Wager, T. D., Davidson, M. L., Hughes, B. L., Lindquist, M. A., 
% Ochsner, K. N.. (2008). Prefrontal-subcortical pathways mediating 
% successful emotion regulation. Neuron, 59, 1037-50.
%
% To load, try the following:

[data_obj, subject_names, image_names] = load_image_set('emotionreg', 'noverbose');

montage(mean(data_obj), 'trans', 'compact2');
drawnow, snapnow

% data_obj is an fmri_data object containing all 30 images.
% subject_names is a list of short names for each image.
% image_names is a list of the full image names with their path.

%% Buckner lab resting-state connectivity maps
%
% A popular series of masks is a set of "networks" developed from resting-state fMRI
% connectivity in 1,000 people. For our purposes, the "network" maps
% consist of a set of voxels that load most highly on each of 7 ICA
% components from the 1,000 Functional Connectomes project. 
% These were published by Randy Buckner's lab in 2011 in three papers:
% Choi et al., Buckner et al., and Yeo et al.  We'll use the cortical
% networks from Yeo et al. here.
%

[bucknermaps, mapnames] = load_image_set('bucknerlab', 'noverbose'); % loads 7 masks from Yeo et al.
disp(char(mapnames))

% Create a montage plot
o2 = montage(get_wh_image(bucknermaps, 1), 'trans', 'compact2', 'color', rand(1, 3));
for i = 2:7, o2 = addblobs(o2, region(get_wh_image(bucknermaps, i)), 'trans', 'color', rand(1, 3)); end
drawnow, snapnow

%% Pain, Cognition, Emotion balanced N = 270 dataset
%
% This dataset is an fmri_data object class object created using CANlab tools (canlab.github.io). 
% It contains 270 single-participant fMRI contrast maps across 18 studies (with 15 participants per study). 
% Studies are grouped into three domains: Pain, Cognitive Control, and Negative Emotion, with 9 studies each. 
% Each domain includes 3 subdomains, with 3 studies each.
%
% The dataset is from Kragel et al. 2018, Nature Neuroscience. 
% It is too large for Github, and it's stored on Neurovault.org
% as collection #504. You could get it using CANlab tools like this:
%
% |[files_on_disk, url_on_neurovault, mycollection, myimages] = retrieve_neurovault_collection(504);|
%
% It is also available on Figshare, with DOI 10.6084/m9.figshare.24033402
% https://figshare.com/ndownloader/files/42143352
%
% If you download from Neurovault, you'd
% have to add metadata for the study category labels to use it.
% Therefore, we suggest you use the CANLab load_image_set() function, as below. 
% It saves a file on your hard drive the first time you run it:
% 
% |kragel_2018_nat_neurosci_270_subjects_test_images.mat|
%
% This file also has metadata that is not necessarily on Neurovault.
% If you save this file somewhere on your Matlab path, you'll be able to
% reload and reuse the dataset easily.

[test_images, names] = load_image_set('kragel18_alldata', 'noverbose');

% This field contains a table object with metadata for each image:
metadata = test_images.metadata_table;

disp('Metadata available in test_images.metadata_table:')
metadata(1:5, :)

% Make a plot of the spatial correlation of the average image for each study

imgs = cellstr(test_images.image_names);
m = mean(test_images);

for i = 1:length(names)
    
    % Create a mean image for each study and store in "m" object.
    
    wh = metadata.Studynumber == i;
    studymean = mean(get_wh_image(test_images, find(wh)));
    m.dat(:, i) = studymean.dat;
    
end

disp('Map of spatial correlations across the mean images for each study');

plot_correlation_matrix(m.dat, 'names', names, 'partitions', [ones(1, 6) 2*ones(1, 6) 3*ones(1, 6)], 'partitionlabels', {'Pain', 'Cognition', 'Emotion'});
drawnow, snapnow

%% Pain across six intensity levels per person (BMRK3)
%
% The dataset contains data from 33 participants, with brain responses to six levels
% of heat (non-painful and painful). Each image is the average over several
% (4-8) trials of heat delivered at a single stimulus intensity, ranging
% from 44.3 - 49.3 degrees C in one-degree increments. Each image is also
% paired with an average reported pain value for that set of trials, rated
% immmediately after heat experience. 
%
% This dataset is interesting for mixed-effects and predictive analyses, as
% it has both within-person and between-person sources of variance.
% 
% Aspects of this data appear in these papers:
% Wager, T.D., Atlas, L.T., Lindquist, M.A., Roy, M., Choong-Wan, W., Kross, E. (2013). 
% An fMRI-Based Neurologic Signature of Physical Pain. The New England Journal of Medicine. 368:1388-1397
% (Study 2)
%
% Woo, C. -W., Roy, M., Buhle, J. T. & Wager, T. D. (2015). Distinct brain systems 
% mediate the effects of nociceptive input and self-regulation on pain. PLOS Biology. 13(1): 
% e1002036. doi:10.1371/journal.pbio.1002036
%
% Lindquist, Martin A., Anjali Krishnan, Marina López-Solà, Marieke Jepma, Choong-Wan Woo, 
% Leonie Koban, Mathieu Roy, et al. 2015. ?Group-Regularized Individual Prediction: 
% Theory and Application to Pain.? NeuroImage. 
% http://www.sciencedirect.com/science/article/pii/S1053811915009982.
%
% This dataset is shared on figshare.com, under this link:
% https://figshare.com/s/ca23e5974a310c44ca93
%
% Here is a direct link to the dataset file with the fmri_data object:
% https://ndownloader.figshare.com/files/12708989
%
% The key variable is image_obj, an fmri_data class object.
% See https://canlab.github.io/
%
% image_obj.dat contains brain data for each image (average across trials)
% image_obj.Y contains pain ratings (one average rating per image)
%
% image_obj.additional_info.subject_id contains integers coding for which
% Load the data file, downloading from figshare if needed

fmri_data_file = which('bmrk3_6levels_pain_dataset.mat');

if isempty(fmri_data_file)
    
    % attempt to download
    disp('Did not find data locally...downloading data file from figshare.com')
    
    fmri_data_file = websave('bmrk3_6levels_pain_dataset.mat', 'https://ndownloader.figshare.com/files/12708989');
    
end

load(fmri_data_file);

descriptives(image_obj);

subject_id = image_obj.additional_info.subject_id;
ratings = reshape(image_obj.Y, 6, 33)';
temperatures = image_obj.additional_info.temperatures;

% Plot the ratings

create_figure('ratings');
title('Pain ratings by stimulus intensity in BMRK3 dataset')
hold on; plot(ratings', '-', 'Color', [.7 .7 .7], 'LineWidth', .5);
lineplot_columns(ratings, 'color', [.7 .3 .3], 'markerfacecolor', [1 .5 0]);
xlabel('Temperature');
ylabel('Rating');
set(gca, 'XTickLabel', [44.3:49.3], 'FontSize', 18);
drawnow, snapnow

%% CANlab 2018 Combined Atlas object
% An atlas-class object is a specialized subclass of fmri_data that stores
% information about a series of parcels, or pre-defined regions, and in
% some cases the probalistic maps that underlie the final parcellation.
%
% A list of pre-defined atlases is contained in the function |load_atlas|.
% The default atlas for some CANlab functions is the "CANlab combined 2018"
% This was created by Tor Wager from other published atlases. It includes:
%
% * Glasser 2016 Nature 180-region cortical parcellation (in MNI space, not indivdidualized)
% * Pauli 2016 PNAS basal ganglia subregions
% * Amygdala/hippocampal and basal forebrain regions from SPM Anatomy Toolbox
% * Thalamus regions from the Morel thalamus atlas
% * Subthalamus/Basal forebrain regions from Pauli "reinforcement learning" HCP atlas
% * Diedrichsen cerebellar atlas regions
% * Multiple named brainstem nuclei localized based on individual papers
% * Additional Shen atlas parcels to cover areas (esp. brainstem) not otherwise named
%
% References for the corresponding papers are stored in the atlas object, and 
% printed in tables generated with the region.table() method.

atlas_obj = load_atlas('canlab2018');

% Create a figure showing cortical parcels
create_figure('iso'); isosurface(atlas_obj, 'alpha', .5);
drawnow, snapnow

% Create a figure of the thalamus regions only
thal = select_atlas_subset(atlas_obj, {'Thal'});
create_figure('iso'); isosurface(thal);
hh = addbrain('hires');
set(hh, 'FaceAlpha', 0.05);
set(gca, 'XLim', [-40 40], 'YLim', [-40 20]);
drawnow, snapnow


%% Kragel 2015 emotion category-predictive patterns
% 
% This loads a series of 7 multivariate patterns from Kragel et al. 2015.
% These patterns were developed to predict emotion categories.
% For our purposes here, we'll just treat them as data images.

[test_dat, names] = load_image_set('kragelemotion', 'noverbose'); % loads 7 masks from Kragel et al.
disp(char(names))

% Plot spatial correlations
plot_correlation_matrix(test_dat.dat, 'names', names);
drawnow, snapnow

%% Subcortical and brainstem regions
% |canlab_load_ROI| has a registry of many named regions derived from previous
% studies. This is particularly useful for loading a subcortical ROI and
% visualizing it or applying it to data.

help canlab_load_ROI

vmpfc = canlab_load_ROI('vmpfc');
nac =  canlab_load_ROI('nac');
pag =  canlab_load_ROI('pag');

create_figure('brain');
isosurface(vmpfc, 'color', {[1 0 1]});
isosurface(nac, 'color', {[1 .5 0]});
isosurface(pag, 'color', {[1 0 0]});
bhan = addbrain('hires right');
view(-119, 5);
drawnow, snapnow


##### SOURCE END #####
--></body></html>