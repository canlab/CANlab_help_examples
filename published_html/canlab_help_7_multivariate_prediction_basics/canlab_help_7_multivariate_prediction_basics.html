
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>canlab_help_7_multivariate_prediction_basics</title><meta name="generator" content="MATLAB 9.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-08-04"><meta name="DC.source" content="canlab_help_7_multivariate_prediction_basics.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">Load dataset with images and print descriptives</a></li><li><a href="#3">Collect some variables we need</a></li><li><a href="#4">Plot the ratings</a></li><li><a href="#5">Prediction</a></li><li><a href="#6">Run the Base model</a></li><li><a href="#7">Plot the results</a></li><li><a href="#8">Summarize within-person classification accuracy</a></li><li><a href="#9">Visualize weight map</a></li><li><a href="#10">Bootstrap weights: Get most reliable weights and p-values for voxels</a></li><li><a href="#11">Try normalizing/scaling data</a></li><li><a href="#12">Try selecting an a priori 'network of interest'</a></li><li><a href="#13">re-run prediction and plot</a></li><li><a href="#14">Other ideas</a></li></ul></div><pre class="codeinput"><span class="comment">% About this dataset</span>
<span class="comment">% -------------------------------------------------------------------------</span>
<span class="comment">%</span>
<span class="comment">% This dataset includes 33 participants, with brain responses to six levels</span>
<span class="comment">% of heat (non-painful and painful).</span>
<span class="comment">%</span>
<span class="comment">% Aspects of this data appear in these papers:</span>
<span class="comment">% Wager, T.D., Atlas, L.T., Lindquist, M.A., Roy, M., Choong-Wan, W., Kross, E. (2013).</span>
<span class="comment">% An fMRI-Based Neurologic Signature of Physical Pain. The New England Journal of Medicine. 368:1388-1397</span>
<span class="comment">% (Study 2)</span>
<span class="comment">%</span>
<span class="comment">% Woo, C. -W., Roy, M., Buhle, J. T. &amp; Wager, T. D. (2015). Distinct brain systems</span>
<span class="comment">% mediate the effects of nociceptive input and self-regulation on pain. PLOS Biology. 13(1):</span>
<span class="comment">% e1002036. doi:10.1371/journal.pbio.1002036</span>
<span class="comment">%</span>
<span class="comment">% Lindquist, Martin A., Anjali Krishnan, Marina L&oacute;pez-Sol&agrave;, Marieke Jepma, Choong-Wan Woo,</span>
<span class="comment">% Leonie Koban, Mathieu Roy, et al. 2015. ?Group-Regularized Individual Prediction:</span>
<span class="comment">% Theory and Application to Pain.? NeuroImage.</span>
<span class="comment">% http://www.sciencedirect.com/science/article/pii/S1053811915009982.</span>
<span class="comment">%</span>
</pre><h2 id="2">Load dataset with images and print descriptives</h2><p>This dataset is shared on figshare.com, under this link: https://figshare.com/s/ca23e5974a310c44ca93</p><p>Here is a direct link to the dataset file with the fmri_data object: https://ndownloader.figshare.com/files/12708989</p><p>The key variable is image_obj This is an fmri_data object from the CANlab Core Tools repository for neuroimaging data analysis. See https://canlab.github.io/</p><p>image_obj.dat contains brain data for each image (average across trials) image_obj.Y contains pain ratings (one average rating per image)</p><p>image_obj.additional_info.subject_id contains integers coding for which Load the data file, downloading from figshare if needed</p><pre class="codeinput">fmri_data_file = which(<span class="string">'bmrk3_6levels_pain_dataset.mat'</span>);

<span class="keyword">if</span> isempty(fmri_data_file)

    <span class="comment">% attempt to download</span>
    disp(<span class="string">'Did not find data locally...downloading data file from figshare.com'</span>)

    fmri_data_file = websave(<span class="string">'bmrk3_6levels_pain_dataset.mat'</span>, <span class="string">'https://ndownloader.figshare.com/files/12708989'</span>);

<span class="keyword">end</span>

load(fmri_data_file);

descriptives(image_obj);
</pre><pre class="codeoutput"> 
Source: BMRK3 dataset from CANlab, PI Tor Wager
Data: .dat contains 6 images per participant, activation estimates during heat on L arm from level 1(44.3 degrees C) to level 6(49.3), in 1 degree increments.
 

____________________________________________________________________________________________________________________________________________
 Wager, T.D., Atlas, L.T., Lindquist, M.A., Roy, M., Choong-Wan, W., Kross, E. (2013). An fMRI-Based Neurologic Signature of Physical Pain. 
The New England Journal of Medicine. 368:1388-1397 (Study 2)                                                                                
                                                                                                                                            
 Woo, C. -W., Roy, M., Buhle, J. T. &amp; Wager, T. D. (2015). Distinct brain systems mediate the effects of nociceptive input and 
self-regulation on pain. PLOS Biology. 13(1): e1002036. doi:10.1371/journal.pbio.1002036                                       
                                                                                                                               
Lindquist, Martin A., Anjali Krishnan, Marina L&oacute;pez-Sol&agrave;, Marieke Jepma, Choong-Wan Woo, Leonie Koban, Mathieu Roy, et al. 2015. 
&#8220;Group-Regularized Individual Prediction: Theory and Application to Pain.&#8221; NeuroImage.                                           
http://www.sciencedirect.com/science/article/pii/S1053811915009982.                                                              
                                                                                                                                 
____________________________________________________________________________________________________________________________________________
 
Summary of dataset
______________________________________________________
Images: 198	Nonempty: 198	Complete: 198
Voxels: 223707	Nonempty: 223707	Complete: 223707
Unique data values: 35583281
 
Min: -11.529	Max: 7.862	Mean: -0.004	Std: 0.227
 
    Percentiles      Values  
    ___________    __________

        0.1            -1.529
        0.5          -0.88055
          1          -0.67632
          5          -0.31891
         25         -0.087519
         50        0.00034864
         75          0.087461
         95           0.29757
         99           0.60449
       99.5           0.77676
       99.9            1.3177

 
</pre><h2 id="3">Collect some variables we need</h2><pre class="codeinput"><span class="comment">% subject_id is useful for cross-validation</span>
<span class="comment">%</span>
<span class="comment">% this used as a custom holdout set in fmri_data.predict() below will</span>
<span class="comment">% implement leave-one-subject-out cross-validation</span>

subject_id = image_obj.additional_info.subject_id;

<span class="comment">% ratings: reconstruct a subjects x temperatures matrix</span>
<span class="comment">% so we can plot it</span>
<span class="comment">%</span>
<span class="comment">% The command below does this only because we have exactly 6 conditions</span>
<span class="comment">% nested within 33 subjects and no missing data.</span>

ratings = reshape(image_obj.Y, 6, 33)';

<span class="comment">% temperatures are 44 - 49 (actually 44.3 - 49.3) in order for each person.</span>

temperatures = image_obj.additional_info.temperatures;
</pre><h2 id="4">Plot the ratings</h2><p>-------------------------------------------------------------------------</p><pre class="codeinput">create_figure(<span class="string">'ratings'</span>);
lineplot_columns(bmrkdata.ratings, <span class="string">'color'</span>, [.7 .3 .3], <span class="string">'markerfacecolor'</span>, [1 .5 0]);
xlabel(<span class="string">'Temperature'</span>);
ylabel(<span class="string">'Rating'</span>);
</pre><img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_01.png" alt=""> <h2 id="5">Prediction</h2><p>There are many options</p><pre class="codeinput"><span class="comment">% Base model: Linear, whole brain prediction</span>
<span class="comment">%</span>
<span class="comment">% Outcome distribution:</span>
<span class="comment">% Continuous: Regression (LASSO-PCR) Categorical/2 choice: SVM, logistic regression</span>
<span class="comment">%</span>
<span class="comment">% Model Options:</span>
<span class="comment">% - Feature selection (part of the brain)</span>
<span class="comment">% - Feature integration (new features)</span>
<span class="comment">%</span>
<span class="comment">% Testing options:</span>
<span class="comment">% - Input data (what level)</span>
<span class="comment">% - Cross-validation</span>
<span class="comment">% - What testing metric (classification accuracy? RMSE?) and at what level</span>
<span class="comment">% (single-trial, condition averages, one-map-per-subject)</span>
<span class="comment">%</span>
<span class="comment">% Inference options:</span>
<span class="comment">% - Component maps, voxel-wise maps</span>
<span class="comment">% - Thresholding (Bootstrapping, Permutation)</span>
<span class="comment">% - Global null hypothesis testing / sanity checks (Permutation)</span>
</pre><h2 id="6">Run the Base model</h2><pre class="codeinput"><span class="comment">% relevant functions:</span>
<span class="comment">% predict method (fmri_data)</span>
<span class="comment">% predict_test_suite method (fmri_data)</span>

<span class="comment">% Define custom holdout set.  If we use subject_id, which is a vector of</span>
<span class="comment">% integers with a unique integer per subject, then we are doing</span>
<span class="comment">% leave-one-subject-out cross-validation.</span>

<span class="comment">% let's build five-fold cross-validation set that leaves out ALL the images</span>
<span class="comment">% from a subject together. That way, we are always predicting out-of-sample</span>
<span class="comment">% (new individuals). If not, dependence across images from the same</span>
<span class="comment">% subjects may invalidate the estimate of predictive accuracy.</span>

holdout_set = zeros(size(subject_id));      <span class="comment">% holdout set membership for each image</span>
n_subjects = length(unique(subject_id));
C = cvpartition(n_subjects, <span class="string">'KFold'</span>, 5);
<span class="keyword">for</span> i = 1:5
    teidx = test(C, i);                     <span class="comment">% which subjects to leave out</span>
    imgidx = ismember(subject_id, find(teidx)); <span class="comment">% all images for these subjects</span>
    holdout_set(imgidx) = i;
<span class="keyword">end</span>

algoname = <span class="string">'cv_lassopcr'</span>; <span class="comment">% cross-validated penalized regression. Predict pain ratings</span>

[cverr, stats, optout] = predict(image_obj, <span class="string">'algorithm_name'</span>, algoname, <span class="string">'nfolds'</span>, holdout_set);
</pre><pre class="codeoutput">Cross-validated prediction with algorithm cv_lassopcr,   5 folds

Completed fit for all data in:   0 hours   0 min  5 secs 
Fold 1/5 done in:   0 hours   0 min  4 sec
Fold 2/5 done in:   0 hours   0 min  4 sec
Fold 3/5 done in:   0 hours   0 min  4 sec
Fold 4/5 done in:   0 hours   0 min  4 sec
Fold 5/5 done in:   0 hours   0 min  4 sec

Total Elapsed Time =   0 hours   0 min 24 sec
</pre><h2 id="7">Plot the results</h2><pre class="codeinput"><span class="comment">% Plot cross-validated predicted outcomes vs. actual</span>

<span class="comment">% Critical fields in stats output structure:</span>
<span class="comment">% stats.Y = actual outcomes</span>
<span class="comment">% stats.yfit = cross-val predicted outcomes</span>
<span class="comment">% pred_outcome_r: Correlation between .yfit and .Y</span>
<span class="comment">% weight_obj: Weight map used for prediction (across all subjects).</span>

<span class="comment">% Continuous outcomes:</span>

create_figure(<span class="string">'scatterplots'</span>, 1, 2);
plot(stats.yfit, stats.Y, <span class="string">'o'</span>)
axis <span class="string">tight</span>
refline
xlabel(<span class="string">'Predicted pain'</span>);
ylabel(<span class="string">'Observed pain'</span>);

<span class="comment">% Consider that each subject has their own line:</span>

<span class="keyword">for</span> i = 1:n
    YY{i} = stats.Y(subject_id == i);
    Yfit{i} = stats.yfit(subject_id == i);
<span class="keyword">end</span>

subplot(1, 2, 2);
line_plot_multisubject(Yfit, YY, <span class="string">'nofigure'</span>);
xlabel(<span class="string">'Predicted pain'</span>);
ylabel(<span class="string">'Observed pain'</span>);
axis <span class="string">tight</span>

<span class="comment">% Yfit is a cell array, one cell per subject, with fitted values for that subject</span>
</pre><pre class="codeoutput">average within-person r = 0.61, t( 32) = 10.76, p = 0.000000, num. missing:   0
</pre><img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_02.png" alt=""> <h2 id="8">Summarize within-person classification accuracy</h2><p>Turn into classification:</p><pre class="codeinput"><span class="comment">% If the stim intensity increases by 1 degree, how often do we correctly</span>
<span class="comment">% predict an increase?</span>
diffs = cellfun(@diff, Yfit, <span class="string">'UniformOutput'</span>, false); <span class="comment">% successive increases in predicted values with increases in stim intensity</span>

<span class="comment">% Subjects (rows) x comparisons (cols), each comparison 1 degree apart</span>
diffs = cat(2, diffs{:})';

acc_per_subject = sum(diffs &gt; 0, 2) ./ size(diffs, 2);
acc_per_comparison = (sum(diffs &gt; 0) ./ size(diffs, 1))';
cohens_d_per_comparison = (mean(diffs) ./ std(diffs))';

fprintf(<span class="string">'Mean acc is : %3.2f%% across all successive 1 degree increments\n'</span>, 100*mean(acc_per_subject));

<span class="comment">% Create and display a table:</span>

comparison = {<span class="string">'45-44'</span> <span class="string">'46-45'</span> <span class="string">'47-46'</span> <span class="string">'48-47'</span> <span class="string">'49-48'</span>}';
results_table = table(comparison, acc_per_comparison, cohens_d_per_comparison);
disp(results_table)

<span class="comment">% 45-44 degrees, 46-45, 47-46, etc.</span>
</pre><pre class="codeoutput">Mean acc is : 72.12% across all successive 1 degree increments
    comparison    acc_per_comparison    cohens_d_per_comparison
    __________    __________________    _______________________

     '45-44'           0.51515                 -0.10353        
     '46-45'           0.72727                  0.65637        
     '47-46'           0.78788                  0.88565        
     '48-47'           0.87879                    1.174        
     '49-48'           0.69697                  0.44796        

</pre><h2 id="9">Visualize weight map</h2><pre class="codeinput">w = stats.weight_obj;  <span class="comment">% This is an image object that we can view, etc.</span>

orthviews(w)

create_figure(<span class="string">'montage'</span>);
o2 = montage(w);
o2 = title_montage(o2, 5, <span class="string">'Predictive model weights'</span>);
</pre><pre class="codeoutput">
SPM12: spm_check_registration (v6245)              23:52:16 - 04/08/2018
========================================================================
Display &lt;a href="matlab:spm_image('display','/Users/torwager/Documents/GitHub/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img,1');"&gt;/Users/torwager/Documents/GitHub/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img,1&lt;/a&gt;
Grouping contiguous voxels:   3 regions

ans =

  1&times;1 cell array

    {1&times;3 region}

Setting up fmridisplay objects
This takes a lot of memory, and can hang if you have too little.
Grouping contiguous voxels:   3 regions
sagittal montage: 4350 voxels displayed, 219357 not displayed on these slices
sagittal montage: 4292 voxels displayed, 219415 not displayed on these slices
sagittal montage: 3990 voxels displayed, 219717 not displayed on these slices
axial montage: 32223 voxels displayed, 191484 not displayed on these slices
axial montage: 34538 voxels displayed, 189169 not displayed on these slices
</pre><img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_03.png" alt=""> <img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_04.png" alt=""> <h2 id="10">Bootstrap weights: Get most reliable weights and p-values for voxels</h2><pre class="codeinput"><span class="comment">% Re-run prediction, adding a 'bootstrap' flag.</span>
<span class="comment">% For a final analysis, at least 5K bootstrap samples is a good idea</span>

<span class="comment">% (This is not run in the example; see help fmri_data.predict for how to</span>
<span class="comment">% run bootstrapping)</span>
</pre><h2 id="11">Try normalizing/scaling data</h2><pre class="codeinput"><span class="comment">% z-score every image, removing the mean and dividing by the std.</span>
<span class="comment">% Remove some scaling noise, but also some signal...</span>
 image_obj = rescale(image_obj, <span class="string">'zscoreimages'</span>);

<span class="comment">% re-run prediction and plot</span>

[cverr, stats, optout] = predict(image_obj, <span class="string">'algorithm_name'</span>, algoname, <span class="string">'nfolds'</span>, holdout_set);

create_figure(<span class="string">'scatterplots'</span>);

<span class="keyword">for</span> i = 1:n
    YY{i} = stats.Y(subject_id == i);
    Yfit{i} = stats.yfit(subject_id == i);
<span class="keyword">end</span>

line_plot_multisubject(Yfit, YY, <span class="string">'nofigure'</span>);
xlabel(<span class="string">'Predicted pain'</span>);
ylabel(<span class="string">'Observed pain'</span>);
axis <span class="string">tight</span>

fprintf(<span class="string">'Overall prediction-outcome correlation is %3.2f\n'</span>, stats.pred_outcome_r)

figure; o2 = montage(stats.weight_obj);
o2 = title_montage(o2, 5, <span class="string">'Predictive model weights'</span>);
</pre><pre class="codeoutput">Cross-validated prediction with algorithm cv_lassopcr,   5 folds

Completed fit for all data in:   0 hours   0 min  6 secs 
Fold 1/5 done in:   0 hours   0 min  4 sec
Fold 2/5 done in:   0 hours   0 min  4 sec
Fold 3/5 done in:   0 hours   0 min  3 sec
Fold 4/5 done in:   0 hours   0 min  4 sec
Fold 5/5 done in:   0 hours   0 min  4 sec

Total Elapsed Time =   0 hours   0 min 24 sec
average within-person r = 0.58, t( 32) = 13.32, p = 0.000000, num. missing:   0
Overall prediction-outcome correlation is 0.58
Setting up fmridisplay objects
This takes a lot of memory, and can hang if you have too little.
Grouping contiguous voxels:   3 regions
sagittal montage: 4350 voxels displayed, 219357 not displayed on these slices
sagittal montage: 4292 voxels displayed, 219415 not displayed on these slices
sagittal montage: 3990 voxels displayed, 219717 not displayed on these slices
axial montage: 32223 voxels displayed, 191484 not displayed on these slices
axial montage: 34538 voxels displayed, 189169 not displayed on these slices
</pre><img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_05.png" alt=""> <img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_06.png" alt=""> <h2 id="12">Try selecting an a priori 'network of interest'</h2><pre class="codeinput"><span class="comment">% re-load</span>
load(<span class="string">'bmrk3_6levels_pain_dataset.mat'</span>, <span class="string">'image_obj'</span>)

<span class="comment">% load an a priori pain-related mask and apply it</span>

mask = fmri_data(which(<span class="string">'pain_2s_z_val_FDR_05.img.gz'</span>)); <span class="comment">% in Neuroimaging_Pattern_Masks repository</span>

image_obj = apply_mask(image_obj, mask);

<span class="comment">% show mean data with mask</span>
m = mean(image_obj);
figure; o2 = montage(m);
o2 = title_montage(o2, 5, <span class="string">'Mean image data, masked'</span>);
</pre><pre class="codeoutput">Using default mask: /Users/torwager/Documents/GitHub/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/brainmask.nii
loading mask. mapping volumes. 
checking that dimensions and voxel sizes of volumes are the same. 
Pre-allocating data array. Needed: 1409312 bytes
Loading image number:     1
Elapsed time is 0.027483 seconds.
Image names entered, but fullpath attribute is empty. Getting path info.
Setting up fmridisplay objects
This takes a lot of memory, and can hang if you have too little.
Grouping contiguous voxels:  27 regions
sagittal montage: 1088 voxels displayed, 47895 not displayed on these slices
sagittal montage: 1171 voxels displayed, 47812 not displayed on these slices
sagittal montage: 980 voxels displayed, 48003 not displayed on these slices
axial montage: 7496 voxels displayed, 41487 not displayed on these slices
axial montage: 7950 voxels displayed, 41033 not displayed on these slices
</pre><img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_07.png" alt=""> <h2 id="13">re-run prediction and plot</h2><pre class="codeinput">[cverr, stats, optout] = predict(image_obj, <span class="string">'algorithm_name'</span>, algoname, <span class="string">'nfolds'</span>, holdout_set);

create_figure(<span class="string">'scatterplots'</span>);

<span class="keyword">for</span> i = 1:n
    YY{i} = stats.Y(subject_id == i);
    Yfit{i} = stats.yfit(subject_id == i);
<span class="keyword">end</span>

line_plot_multisubject(Yfit, YY, <span class="string">'nofigure'</span>);
xlabel(<span class="string">'Predicted pain'</span>);
ylabel(<span class="string">'Observed pain'</span>);
axis <span class="string">tight</span>

fprintf(<span class="string">'Overall prediction-outcome correlation is %3.2f\n'</span>, stats.pred_outcome_r)

figure; o2 = montage(stats.weight_obj);
o2 = title_montage(o2, 5, <span class="string">'Predictive model weights'</span>);
</pre><pre class="codeoutput">Cross-validated prediction with algorithm cv_lassopcr,   5 folds

Completed fit for all data in:   0 hours   0 min  1 secs 
Fold 1/5 done in:   0 hours   0 min  1 sec
Fold 2/5 done in:   0 hours   0 min  1 sec
Fold 3/5 done in:   0 hours   0 min  1 sec
Fold 4/5 done in:   0 hours   0 min  1 sec
Fold 5/5 done in:   0 hours   0 min  1 sec

Total Elapsed Time =   0 hours   0 min  4 sec
average within-person r = 0.58, t( 32) = 7.17, p = 0.000000, num. missing:   0
Overall prediction-outcome correlation is 0.58
Setting up fmridisplay objects
This takes a lot of memory, and can hang if you have too little.
Grouping contiguous voxels:  27 regions
sagittal montage: 1088 voxels displayed, 47895 not displayed on these slices
sagittal montage: 1171 voxels displayed, 47812 not displayed on these slices
sagittal montage: 980 voxels displayed, 48003 not displayed on these slices
axial montage: 7496 voxels displayed, 41487 not displayed on these slices
axial montage: 7950 voxels displayed, 41033 not displayed on these slices
</pre><img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_08.png" alt=""> <img vspace="5" hspace="5" src="canlab_help_7_multivariate_prediction_basics_09.png" alt=""> <h2 id="14">Other ideas</h2><p>There are many ways to build from this basic analysis.</p><pre class="codeinput"><span class="comment">% Data</span>
<span class="comment">% ------------</span>
<span class="comment">% Examine/clean outliers</span>
<span class="comment">% Transformations of data: Scaling/centering to remove global mean,</span>
<span class="comment">% ventricle mean</span>
<span class="comment">% Identify unaccounted sources of variation/subgroups (experimenter sex,</span>
<span class="comment">% etc.)</span>

<span class="comment">% Features</span>
<span class="comment">% ------------</span>
<span class="comment">% A priori regions / meta-analysis</span>
<span class="comment">% Feature selection in cross-val loop: Univariate, recursive feature elim</span>
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2018a</a><br></p></div><!--
##### SOURCE BEGIN #####

% About this dataset
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
%
% This dataset includes 33 participants, with brain responses to six levels
% of heat (non-painful and painful).  
% 
% Aspects of this data appear in these papers:
% Wager, T.D., Atlas, L.T., Lindquist, M.A., Roy, M., Choong-Wan, W., Kross, E. (2013). 
% An fMRI-Based Neurologic Signature of Physical Pain. The New England Journal of Medicine. 368:1388-1397
% (Study 2)
%
% Woo, C. -W., Roy, M., Buhle, J. T. & Wager, T. D. (2015). Distinct brain systems 
% mediate the effects of nociceptive input and self-regulation on pain. PLOS Biology. 13(1): 
% e1002036. doi:10.1371/journal.pbio.1002036
%
% Lindquist, Martin A., Anjali Krishnan, Marina López-Solà, Marieke Jepma, Choong-Wan Woo, 
% Leonie Koban, Mathieu Roy, et al. 2015. ?Group-Regularized Individual Prediction: 
% Theory and Application to Pain.? NeuroImage. 
% http://www.sciencedirect.com/science/article/pii/S1053811915009982.
%
%% Load dataset with images and print descriptives
% This dataset is shared on figshare.com, under this link:
% https://figshare.com/s/ca23e5974a310c44ca93
%
% Here is a direct link to the dataset file with the fmri_data object:
% https://ndownloader.figshare.com/files/12708989
%
% The key variable is image_obj
% This is an fmri_data object from the CANlab Core Tools repository for neuroimaging data analysis.
% See https://canlab.github.io/
%
% image_obj.dat contains brain data for each image (average across trials)
% image_obj.Y contains pain ratings (one average rating per image)
%
% image_obj.additional_info.subject_id contains integers coding for which
% Load the data file, downloading from figshare if needed

fmri_data_file = which('bmrk3_6levels_pain_dataset.mat');

if isempty(fmri_data_file)
    
    % attempt to download
    disp('Did not find data locally...downloading data file from figshare.com')
    
    fmri_data_file = websave('bmrk3_6levels_pain_dataset.mat', 'https://ndownloader.figshare.com/files/12708989');
    
end

load(fmri_data_file);

descriptives(image_obj);

%% Collect some variables we need

% subject_id is useful for cross-validation
%
% this used as a custom holdout set in fmri_data.predict() below will
% implement leave-one-subject-out cross-validation

subject_id = image_obj.additional_info.subject_id;

% ratings: reconstruct a subjects x temperatures matrix
% so we can plot it
%
% The command below does this only because we have exactly 6 conditions
% nested within 33 subjects and no missing data. 

ratings = reshape(image_obj.Y, 6, 33)';

% temperatures are 44 - 49 (actually 44.3 - 49.3) in order for each person.

temperatures = image_obj.additional_info.temperatures;

%% Plot the ratings
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-  

create_figure('ratings');
lineplot_columns(bmrkdata.ratings, 'color', [.7 .3 .3], 'markerfacecolor', [1 .5 0]);
xlabel('Temperature');
ylabel('Rating');


%% Prediction
% There are many options

% Base model: Linear, whole brain prediction
% 
% Outcome distribution:
% Continuous: Regression (LASSO-PCR) Categorical/2 choice: SVM, logistic regression
%
% Model Options:
% - Feature selection (part of the brain)
% - Feature integration (new features)
%
% Testing options:
% - Input data (what level)
% - Cross-validation
% - What testing metric (classification accuracy? RMSE?) and at what level
% (single-trial, condition averages, one-map-per-subject)
%
% Inference options:
% - Component maps, voxel-wise maps
% - Thresholding (Bootstrapping, Permutation)
% - Global null hypothesis testing / sanity checks (Permutation)

%% Run the Base model

% relevant functions:
% predict method (fmri_data)                            
% predict_test_suite method (fmri_data) 

% Define custom holdout set.  If we use subject_id, which is a vector of
% integers with a unique integer per subject, then we are doing
% leave-one-subject-out cross-validation. 

% let's build five-fold cross-validation set that leaves out ALL the images
% from a subject together. That way, we are always predicting out-of-sample
% (new individuals). If not, dependence across images from the same
% subjects may invalidate the estimate of predictive accuracy.

holdout_set = zeros(size(subject_id));      % holdout set membership for each image
n_subjects = length(unique(subject_id));
C = cvpartition(n_subjects, 'KFold', 5);
for i = 1:5
    teidx = test(C, i);                     % which subjects to leave out
    imgidx = ismember(subject_id, find(teidx)); % all images for these subjects
    holdout_set(imgidx) = i;
end

algoname = 'cv_lassopcr'; % cross-validated penalized regression. Predict pain ratings

[cverr, stats, optout] = predict(image_obj, 'algorithm_name', algoname, 'nfolds', holdout_set);

%% Plot the results

% Plot cross-validated predicted outcomes vs. actual

% Critical fields in stats output structure:
% stats.Y = actual outcomes
% stats.yfit = cross-val predicted outcomes
% pred_outcome_r: Correlation between .yfit and .Y
% weight_obj: Weight map used for prediction (across all subjects).
                 
% Continuous outcomes:

create_figure('scatterplots', 1, 2);
plot(stats.yfit, stats.Y, 'o')
axis tight
refline
xlabel('Predicted pain');
ylabel('Observed pain');

% Consider that each subject has their own line:

for i = 1:n
    YY{i} = stats.Y(subject_id == i);
    Yfit{i} = stats.yfit(subject_id == i);
end

subplot(1, 2, 2);
line_plot_multisubject(Yfit, YY, 'nofigure');
xlabel('Predicted pain');
ylabel('Observed pain');
axis tight

% Yfit is a cell array, one cell per subject, with fitted values for that subject

%% Summarize within-person classification accuracy
% 
% Turn into classification:

% If the stim intensity increases by 1 degree, how often do we correctly
% predict an increase?
diffs = cellfun(@diff, Yfit, 'UniformOutput', false); % successive increases in predicted values with increases in stim intensity

% Subjects (rows) x comparisons (cols), each comparison 1 degree apart
diffs = cat(2, diffs{:})';

acc_per_subject = sum(diffs > 0, 2) ./ size(diffs, 2);
acc_per_comparison = (sum(diffs > 0) ./ size(diffs, 1))';
cohens_d_per_comparison = (mean(diffs) ./ std(diffs))';

fprintf('Mean acc is : %3.2f%% across all successive 1 degree increments\n', 100*mean(acc_per_subject));

% Create and display a table:

comparison = {'45-44' '46-45' '47-46' '48-47' '49-48'}';
results_table = table(comparison, acc_per_comparison, cohens_d_per_comparison);
disp(results_table)

% 45-44 degrees, 46-45, 47-46, etc.

%% Visualize weight map

w = stats.weight_obj;  % This is an image object that we can view, etc.

orthviews(w)

create_figure('montage');
o2 = montage(w);
o2 = title_montage(o2, 5, 'Predictive model weights');


%% Bootstrap weights: Get most reliable weights and p-values for voxels

% Re-run prediction, adding a 'bootstrap' flag. 
% For a final analysis, at least 5K bootstrap samples is a good idea

% (This is not run in the example; see help fmri_data.predict for how to
% run bootstrapping)

%% Try normalizing/scaling data

% z-score every image, removing the mean and dividing by the std.
% Remove some scaling noise, but also some signal...
 image_obj = rescale(image_obj, 'zscoreimages');

% re-run prediction and plot

[cverr, stats, optout] = predict(image_obj, 'algorithm_name', algoname, 'nfolds', holdout_set);

create_figure('scatterplots');

for i = 1:n
    YY{i} = stats.Y(subject_id == i);
    Yfit{i} = stats.yfit(subject_id == i);
end

line_plot_multisubject(Yfit, YY, 'nofigure');
xlabel('Predicted pain');
ylabel('Observed pain');
axis tight

fprintf('Overall prediction-outcome correlation is %3.2f\n', stats.pred_outcome_r)

figure; o2 = montage(stats.weight_obj);
o2 = title_montage(o2, 5, 'Predictive model weights');

%% Try selecting an a priori 'network of interest'

% re-load
load('bmrk3_6levels_pain_dataset.mat', 'image_obj')

% load an a priori pain-related mask and apply it

mask = fmri_data(which('pain_2s_z_val_FDR_05.img.gz')); % in Neuroimaging_Pattern_Masks repository

image_obj = apply_mask(image_obj, mask);

% show mean data with mask
m = mean(image_obj);
figure; o2 = montage(m);
o2 = title_montage(o2, 5, 'Mean image data, masked');


%% re-run prediction and plot

[cverr, stats, optout] = predict(image_obj, 'algorithm_name', algoname, 'nfolds', holdout_set);

create_figure('scatterplots');

for i = 1:n
    YY{i} = stats.Y(subject_id == i);
    Yfit{i} = stats.yfit(subject_id == i);
end

line_plot_multisubject(Yfit, YY, 'nofigure');
xlabel('Predicted pain');
ylabel('Observed pain');
axis tight

fprintf('Overall prediction-outcome correlation is %3.2f\n', stats.pred_outcome_r)

figure; o2 = montage(stats.weight_obj);
o2 = title_montage(o2, 5, 'Predictive model weights');

%% Other ideas
% There are many ways to build from this basic analysis.

% Data
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH
% Examine/clean outliers
% Transformations of data: Scaling/centering to remove global mean,
% ventricle mean
% Identify unaccounted sources of variation/subgroups (experimenter sex,
% etc.)

% Features
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH
% A priori regions / meta-analysis
% Feature selection in cross-val loop: Univariate, recursive feature elim


##### SOURCE END #####
--></body></html>